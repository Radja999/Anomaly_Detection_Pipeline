{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1– Paths and Configuration**"
      ],
      "metadata": {
        "id": "lqnBIBW3fG1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQZxfrsbcTy2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "from scipy.stats import ks_2samp\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Project paths\n",
        "BASE_DIR = \"Anomaly_Detection_Pipeline\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "\n",
        "PUBLIC_BENIGN_FILE = os.path.join(DATA_DIR, \"public_benign_set.csv\")\n",
        "PRIVATE_BENIGN_FILE = os.path.join(DATA_DIR, \"private_benign_set.csv\")\n",
        "ATTACK_FILE = os.path.join(DATA_DIR, \"attack_set.csv\")\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(MODEL_DIR, \"best_autoencoder.pt\")\n",
        "SCHEMA_PATH = os.path.join(MODEL_DIR, \"schema.pkl\")\n",
        "BOUNDS_PATH = os.path.join(MODEL_DIR, \"bounds.pkl\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2– Load Model, Schema, and Bounds**"
      ],
      "metadata": {
        "id": "ItUhuOkTfPha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(SCHEMA_PATH, \"rb\") as f:\n",
        "    schema = pickle.load(f)\n",
        "with open(BOUNDS_PATH, \"rb\") as f:\n",
        "    bounds = pickle.load(f)\n",
        "\n",
        "cat_feature = schema[\"cat_feature\"]\n",
        "cont_cols = schema[\"cont_cols\"]\n",
        "minmax_features = schema[\"minmax_features\"]\n",
        "no_scale_features = schema[\"no_scale_features\"]\n",
        "\n",
        "class DeepAutoencoder(nn.Module):\n",
        "    def __init__(self, n_cont, max_ports=65535, emb_dim=128, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_embeddings=max_ports + 1, embedding_dim=emb_dim)\n",
        "        in_dim = n_cont + emb_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(in_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 256), nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, n_cont)\n",
        "        )\n",
        "    def forward(self, cat, cont):\n",
        "        emb = self.emb(cat)\n",
        "        x = torch.cat([emb, cont], dim=1)\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "model = DeepAutoencoder(len(cont_cols), max_ports=65535, emb_dim=128, latent_dim=128).to(device)\n",
        "model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model and schema successfully loaded.\")\n"
      ],
      "metadata": {
        "id": "Ua4HX_ROfPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3– Load Processed Datasets**"
      ],
      "metadata": {
        "id": "HMTynZ1rfYWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_public = pd.read_csv(PUBLIC_BENIGN_FILE)\n",
        "df_attack = pd.read_csv(ATTACK_FILE)\n",
        "df_private = pd.read_csv(PRIVATE_BENIGN_FILE)\n",
        "\n",
        "print(f\"Public Benign: {df_public.shape}, Attack: {df_attack.shape}, Private Benign: {df_private.shape}\")\n"
      ],
      "metadata": {
        "id": "ctY2ryaVfYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4– Helper Functions for Preprocessing**"
      ],
      "metadata": {
        "id": "eP2JrLayfem7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_safe(x):\n",
        "    return np.log1p(np.clip(x, a_min=0, a_max=None))\n",
        "\n",
        "def apply_log_scaling(df, features):\n",
        "    df_scaled = df.copy()\n",
        "    for col in features:\n",
        "        if col in df_scaled.columns:\n",
        "            df_scaled[col] = log_safe(df_scaled[col].values)\n",
        "    return df_scaled\n",
        "\n",
        "def robust_minmax_transform(df, bounds, exclude_cols=None):\n",
        "    df_scaled = df.copy()\n",
        "    for col, (lower, upper) in bounds.items():\n",
        "        if col not in df_scaled.columns:\n",
        "            continue\n",
        "        if exclude_cols and col in exclude_cols:\n",
        "            df_scaled[col] = 0.0\n",
        "            continue\n",
        "        if upper == lower or (upper - lower) < 1e-9:\n",
        "            df_scaled[col] = 0.0\n",
        "        else:\n",
        "            x = np.clip(df_scaled[col].values, lower, upper)\n",
        "            df_scaled[col] = (x - lower) / (upper - lower)\n",
        "    return df_scaled.fillna(0.0)\n",
        "\n",
        "# Constant columns in the private dataset\n",
        "constant_cols = [\n",
        "    \"min_seg_size_forward\", \"Flow IAT Min\", \"Fwd URG Flags\", \"URG Flag Count\",\n",
        "    \"ECE Flag Count\", \"Active Max\", \"Active Min\", \"Active Mean\", \"Active Std\",\n",
        "    \"Idle Max\", \"Idle Min\", \"Idle Mean\", \"Idle Std\", \"CWE Flag Count\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "muDsBl5SfeyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5– Function to Compute MSE Errors**"
      ],
      "metadata": {
        "id": "ii1f-CefflbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mse_errors(df, name=\"dataset\"):\n",
        "    df_scaled = apply_log_scaling(df, minmax_features)\n",
        "    for col in no_scale_features:\n",
        "        if col in df.columns:\n",
        "            df_scaled[col] = df[col].astype(np.float32)\n",
        "    df_scaled[cat_feature] = df[cat_feature].astype(np.int64)\n",
        "    df_scaled = robust_minmax_transform(df_scaled, bounds, exclude_cols=constant_cols)\n",
        "    for c in cont_cols:\n",
        "        if c not in df_scaled.columns:\n",
        "            df_scaled[c] = 0.0\n",
        "    df_scaled = df_scaled[[cat_feature] + cont_cols]\n",
        "\n",
        "    cat_tensor = torch.tensor(df_scaled[cat_feature].values, dtype=torch.long)\n",
        "    cont_tensor = torch.tensor(df_scaled[cont_cols].values, dtype=torch.float32)\n",
        "    loader = DataLoader(TensorDataset(cat_tensor, cont_tensor), batch_size=1024, shuffle=False)\n",
        "\n",
        "    mse_list = []\n",
        "    with torch.no_grad():\n",
        "        for cat, cont in loader:\n",
        "            cat, cont = cat.to(device), cont.to(device)\n",
        "            output = model(cat, cont)\n",
        "            mse_batch = torch.mean((output - cont) ** 2, dim=1).cpu().numpy()\n",
        "            mse_list.extend(mse_batch)\n",
        "\n",
        "    mse_arr = np.array(mse_list)\n",
        "    print(f\"Evaluated {len(mse_arr)} samples from {name}.\")\n",
        "    return mse_arr\n"
      ],
      "metadata": {
        "id": "4lA3_u0jfrGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6– Evaluate on Attack Dataset**"
      ],
      "metadata": {
        "id": "ys8O4AaXftfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_attack[\"Label_Binary\"] = (df_attack[\"Label\"] != \"BENIGN\").astype(int)\n",
        "df_mixed = pd.concat([df_public.assign(Label_Binary=0), df_attack])\n",
        "\n",
        "cat_tensor = torch.tensor(df_mixed[cat_feature].astype(int).values, dtype=torch.long)\n",
        "cont_tensor = torch.tensor(df_mixed[cont_cols].astype(np.float32).values, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(df_mixed[\"Label_Binary\"].values, dtype=torch.int)\n",
        "\n",
        "mixed_loader = DataLoader(TensorDataset(cat_tensor, cont_tensor, labels_tensor), batch_size=1024, shuffle=False)\n",
        "\n",
        "recon_errors, true_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for cat, cont, labels in mixed_loader:\n",
        "        cat, cont = cat.to(device), cont.to(device)\n",
        "        output = model(cat, cont)\n",
        "        batch_err = torch.mean((output - cont) ** 2, dim=1).cpu().numpy()\n",
        "        recon_errors.extend(batch_err)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "recon_errors = np.array(recon_errors)\n",
        "true_labels = np.array(true_labels)\n",
        "print(f\"Inference complete on {len(recon_errors)} samples.\")\n",
        "\n",
        "roc_auc = roc_auc_score(true_labels, recon_errors)\n",
        "precision, recall, thresholds_pr = precision_recall_curve(true_labels, recon_errors)\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"ROC AUC: {roc_auc:.4f} | PR AUC: {pr_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "h9i27oHFftp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7– Visualizations for Attack vs Benign**"
      ],
      "metadata": {
        "id": "x_2em0mDf0gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(recon_errors[true_labels==0], bins=100, color='green', alpha=0.6, label='Benign')\n",
        "sns.histplot(recon_errors[true_labels==1], bins=100, color='red', alpha=0.5, label='Attack')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Reconstruction Error (MSE)\")\n",
        "plt.ylabel(\"Frequency (log scale)\")\n",
        "plt.title(\"Reconstruction Error Distribution\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fpr, tpr, _ = roc_curve(true_labels, recon_errors)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0,1], [0,1], '--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(recall, precision, color='purple', label=f'PR (AUC = {pr_auc:.4f})')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_NPIlMFf0q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8– Compare Public vs Private Benign MSEs**"
      ],
      "metadata": {
        "id": "jD229pNzf7Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_public = compute_mse_errors(df_public, name=\"public benign\")\n",
        "mse_private = compute_mse_errors(df_private, name=\"private benign\")\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Dataset\": [\"Public\", \"Private\"],\n",
        "    \"Mean\": [np.mean(mse_public), np.mean(mse_private)],\n",
        "    \"Median\": [np.median(mse_public), np.median(mse_private)],\n",
        "    \"Std\": [np.std(mse_public), np.std(mse_private)],\n",
        "    \"Min\": [np.min(mse_public), np.min(mse_private)],\n",
        "    \"Max\": [np.max(mse_public), np.max(mse_private)]\n",
        "})\n",
        "display(summary)\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.kdeplot(mse_public, color='blue', fill=True, label='Public Benign')\n",
        "sns.kdeplot(mse_private, color='orange', fill=True, label='Private Benign')\n",
        "plt.xscale('log')\n",
        "plt.xlabel(\"Reconstruction Error (MSE)\")\n",
        "plt.ylabel(\"Density (log scale)\")\n",
        "plt.title(\"Reconstruction Error Comparison – Public vs Private Benign\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sI1CtO08f7jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9– Statistical Divergence Analysis**"
      ],
      "metadata": {
        "id": "O40f430GgFMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks_stat, ks_p = ks_2samp(mse_public, mse_private)\n",
        "print(f\"KS Statistic: {ks_stat:.4f}, p-value: {ks_p:.4e}\")\n",
        "\n",
        "bins = np.logspace(\n",
        "    np.log10(min(mse_public.min(), mse_private.min()) + 1e-9),\n",
        "    np.log10(max(mse_public.max(), mse_private.max()) + 1e-9),\n",
        "    200\n",
        ")\n",
        "hist_pub, _ = np.histogram(mse_public, bins=bins, density=True)\n",
        "hist_priv, _ = np.histogram(mse_private, bins=bins, density=True)\n",
        "\n",
        "hist_pub /= np.sum(hist_pub)\n",
        "hist_priv /= np.sum(hist_priv)\n",
        "overlap_area = np.sum(np.minimum(hist_pub, hist_priv))\n",
        "\n",
        "print(f\"Overlap Area: {overlap_area:.4f}\")\n",
        "if overlap_area < 0.5:\n",
        "    print(\"Strong distributional divergence detected.\")\n",
        "elif overlap_area < 0.8:\n",
        "    print(\"Moderate divergence detected.\")\n",
        "else:\n",
        "    print(\"High similarity detected between distributions.\")\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.histplot(mse_public, bins=bins, color='blue', alpha=0.5, label='Public', stat='density')\n",
        "sns.histplot(mse_private, bins=bins, color='orange', alpha=0.5, label='Private', stat='density')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Reconstruction Error (MSE)\")\n",
        "plt.ylabel(\"Density (log scale)\")\n",
        "plt.title(\"MSE Distribution Comparison (Log-Log Scale)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "cdf_pub = np.cumsum(hist_pub) / np.sum(hist_pub)\n",
        "cdf_priv = np.cumsum(hist_priv) / np.sum(hist_priv)\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(bins[:-1], np.abs(cdf_pub - cdf_priv), color='red', lw=2)\n",
        "plt.xscale('log')\n",
        "plt.xlabel(\"Reconstruction Error (MSE)\")\n",
        "plt.ylabel(\"|ΔCDF|\")\n",
        "plt.title(\"Absolute CDF Difference – Public vs Private Benign Sets\")\n",
        "plt.grid(True, which=\"both\", ls=\"--\", lw=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lm8jfRIcgFWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}